#增强学习
##连续状态
增强学习处理的事务很多情况下是连续变量，而之前的算法是解决离散问题的。

一种方法是将连续的状态切割为多个离散的状态，称**离散化**。离散化的问题在于状态数量过多，一至二维的离散化还能使模型正常运作，而六维以上的模型离散化后几乎无法运作。

##学习模型
将整个模型假想成一个黑盒，前一状态为$s_t$，执行动作$a_t$后，下一状态为一随机变量$s_{t+1} \sim P_{s_{t}a_{t}}$。

要得到这个模型，一种方式是使用物理手动建模。比如杆与小车的问题，可以通过数学方法得到下一时刻的小车状态（欧拉解法即可）。

另外一种方法是通过收集到的数据学习得到一个模型。假定执行$m$次实验，每次实验进行$T$个时间间隔。这个过程可以通过执行随机动作，或者执行某个特定的策略，或者随便其他什么方法。之后可以得到这样的$m$个序列：
$$
\begin{aligned}
s_0^{\left ( 1 \right )}\overset{a_0}{\rightarrow}s_1^{\left ( 1 \right )}\overset{a_1}{\rightarrow}&s_2^{\left ( 1 \right )}\overset{a_2}{\rightarrow}\dots\overset{a_{T-1}}{\rightarrow}s_T^{\left ( 1 \right )}\\
s_0^{\left ( 2 \right )}\overset{a_0}{\rightarrow}s_1^{\left ( 2 \right )}\overset{a_1}{\rightarrow}&s_2^{\left ( 2 \right )}\overset{a_2}{\rightarrow}\dots\overset{a_{T-1}}{\rightarrow}s_T^{\left ( 2 \right )}\\
&\vdots\\
s_0^{\left ( m \right )}\overset{a_0}{\rightarrow}s_1^{\left ( m \right )}\overset{a_1}{\rightarrow}&s_2^{\left ( m \right )}\overset{a_2}{\rightarrow}\dots\overset{a_{T-1}}{\rightarrow}s_T^{\left ( m \right )}
\end{aligned}
$$
然后使用学习算法估计$s_{t+1}$为关于$s_t$和$a_t$的一个函数。

**例子**：假定线性模型，$s_{t+1} = As_t+Ba_t$，取：
$$\arg\min_{A,B}\sum_{i=1}^{m}\sum_{t=0}^{t-1}\left\| s_{t+1}^{\left ( i \right )}-\left( As_t^{\left ( i \right )}+Ba_t^{\left ( i \right )} \right) \right\|^2$$
可以简单地认为这是一个**决定性**模型，或者可以将这个模型视作**随机**模型。
$$s_{t+1} = As_t+Ba_t+\epsilon_t$$
通常，$\epsilon_t \sim \mathcal{N}\left( 0,\Sigma \right)$。

更宽泛地，可以选择$\phi\left( s \right)$来产生更复杂的学习特征。

###适应价值迭代

1. 随机采样$m$个状态$s^{\left( 1 \right)},s^{\left( 1 \right)},\dots,s^{\left( m \right)} \in S$；
2. 初始化$\theta := 0$；
3. 重复：
    a. 对于$i = 1,\dots,m$：
        i. 对于任意行动$a \in A$：
            1) 采样$s_1',\dots,s_k' \sim P_{s^{\left( i \right)}a}$（采用任意MDP模型）；
            2) 设置$q\left ( a \right ) = \frac{1}{k}\sum_{j=1}^{k}R\left ( s^{\left ( i \right )} \right )+\gamma V\left ( s_j' \right )$；  
                //如此，$q\left ( a \right )$为$R\left ( s^{\left ( i \right )} \right )+\gamma E_{s' \sim P_{s^{\left ( i \right )}a}}\left [ V\left ( s' \right ) \right ]$的估计
        ii. 设置$y^{\left ( i \right )} = \max_a q\left ( a \right )$；  
            //如此，$y^{\left ( i \right )}$为$R\left ( s^{\left ( i \right )} \right )+\gamma\max_a E_{s' \sim P_{s^{\left ( i \right )}a}}\left [ V\left ( s' \right ) \right ]$的估计
    b. 设置$\theta := \arg\min_\theta\frac{1}{2}\sum_{i=1}^{m}\left ( \theta^T\phi\left ( s^{\left ( i \right )} \right )-y^{\left ( i \right )} \right )^2$

