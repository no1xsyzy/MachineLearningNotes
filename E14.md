#因子分析
##因子分析模型
处理$\left(x,z\right)$上的联合分布。
$$
\begin{aligned}
z&\sim\mathcal{N}\left( 0,I \right)\\
x|z&\sim\mathcal{N}\left( \mu+\Lambda z,\Psi \right)\\
\begin{bmatrix}
z\\
x
\end{bmatrix} &\sim \mathcal{N}\left( 
\begin{bmatrix}
\vec{0}\\
\mu
\end{bmatrix},
\begin{bmatrix}
I & \Lambda^T \\ 
\Lambda & \Lambda\Lambda^T+\Psi
\end{bmatrix}
\right)
\end{aligned}
$$
导致整个似然性公式非常复杂，希望直接处理整个方程非常困难。

##因子分析的期望最大化
<http://cs229.stanford.edu/notes/cs229-notes9.pdf>第6页第4章节。

#主成分分析（PCA）
一些特征间可能存在内在联系，那么两者在一个方向上具有较高的方差，对应正交方向上则具有很低的方差。
希望可以有自动处理的方式。

##预处理
标准化平均值为0和方差为1。

1. 使得$\mu = \frac{1}{m}\sum_{i=1}^{m}x^{\left( i \right)}$
2. 替换$x^{\left( i \right)}$为$x^{\left( i \right)}-\mu$
3. 使得$\sigma_j^2 = \frac{1}{m}\sum_i\left( x_j^{\left( i \right)} \right)^2$
4. 替换$x_j^{\left( i \right)}$为$x_j^{\left( i \right)}/\sigma_j$

##选取投影方向
正确的投影方向上方差大，所以选取的$u$符合：
$$
\begin{aligned}
u &= \arg\max_{u:\left\| u \right\|=1}\frac{1}{m}\sum_{i=1}^{m}\left( {x^{\left( i \right)}}^T u \right)^2\\
\frac{1}{m}\sum_{i=1}^{m}\left( {x^{\left( i \right)}}^T u \right)^2 &= \frac{1}{m}\sum_{i=1}^{m}u^Tx^{\left( i \right)}{x^{\left( i \right)}}^T u\\
 &= u^T\left( \frac{1}{m}\sum_{i=1}^{m}x^{\left( i \right)}{x^{\left( i \right)}}^T \right)u\\
&\Rightarrow u\textup{ 是 }\Sigma=\frac{1}{m}\sum_{i=1}^{m}x^{\left( i \right)}{x^{\left( i \right)}}^T\textup{ 的主特征向量 }
\end{aligned}
$$

如果需要一个$k$维的子空间，选择$\Sigma$的前$k$个特征向量$u_1,\dots,u_k$

##主成分分析作用

* 帮助可视化（人类基本只能理解三维以下）
* 压缩数据量（消除大量无用信息）
* 学习过程（消除无关噪音）
* 异常数据检测（如果一个数据不在主成分分析出的子空间上，很有可能是异常数据）
* 优化匹配距离计算（两个数据的相似性应对在子空间上的投影计算）

