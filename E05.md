E05-生成学习算法
====

2017-06-28

生成学习算法（Generative Learning algorithms）
----

与之前的算法不同，生成学习算法尝试生成分类目标的特征模型，然后测试新数据与模型的吻合程度。
根据贝叶斯法则，
$$p\left(y|x\right)=\frac{p\left(x|y\right)p\left(y\right)}{p\left(x\right)}$$

高斯判别分析（Gaussian discriminant analysis）
----

在很多情况下特征符合或者近似符合多维高斯分布，所以可以简单地使用推导结果[^1]

[^1]: <http://cs229.stanford.edu/notes/cs229-notes2.pdf> Page 6

朴素贝叶斯（Naive Bayes）
----

* 问题：垃圾邮件分类
* 建模：假定有一组n个单词。每一封邮件的特征提取为“是否存在这一个单词”的n维列向量。
* 假设：知道是否为垃圾邮件的情况下，单词的存在于否之间不存在相关性。
* 推倒得出：
$$
\begin{aligned}
p\left( y=1|x \right) &= \frac{ p\left( x|y=1 \right) p\left( y=1 \right) }{ p\left( x \right) }\\
&=\frac{ \left( \prod^n_{i=1}p\left( x_i|y=1 \right) \right) p\left( y=1 \right) }{ \left( \prod^n_{i=1}p\left( x_i|y=1 \right) \right) p\left( y=1 \right) + \left( \prod^n_{i=1}p\left( x_i|y=0 \right) \right) p\left( y=0 \right) }
\end{aligned}
$$

拉普拉斯平滑（Laplace smoothing）
----

比如，统计上得到了5次零，那么第6次是零的概率是多少？

* 经典的处理方式是计算频率作为概率：$\phi_j=\frac{\sum^m_{i=1}1\left\{ z^{\left(i\right)} =j \right\} }{m}$
    - 这种处理方式的问题是：如果不发生，即 $\forall i\in\left\{1,2,\ldots,m\right\}, z^{\left(i\right)} \neq j$
    - 频率是零，导致计算得到的概率也是零，那么接下来这件事情不会发生。这样的计算方式显然是不合理的。
* 拉普拉斯平滑，将每种情况的计数增加一：$\phi_j=\frac{\sum^m_{i=1}1\left\{ z^{\left(i\right)} =j \right\}+1 }{m+k}$
    - 即使不发生的情况也有概率，同时又保证了各个性质不变。
