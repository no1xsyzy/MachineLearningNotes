学习理论
====

偏差/方差权衡
----

如第一讲中所述，

*如果设定假设过于简单，大多数的训练样本不在拟合曲线上，数据误差较大，称欠拟合。
*如果设定假设过于复杂，无法表现变化趋势，称过拟合。

这两者均有很大的泛化误差（generalization error）。

* 误差偏差意味着，在训练集趋向于无穷大的时候依旧会出现的误差。
* 误差方差是指仅在数据量很小的情况下会产生的误差。

###引理1
使得$A_1,A_2,\dots,A_k$是$k$个不同的事件（相关性不作假设），有
$$P\left( A_1 \cup \dots \cup A_k \right) \leq P\left( A_1 \right)+\dots+P\left( A_k \right)$$

###引理2
使得$Z_1,\dots,Z_m$为$m$个独立恒等分布随机变量，
且遵循伯努利$\mathrm{Bernoulli}\left( \phi \right)$分布。
即$P\left( Z_i=1 \right)=\phi$且$P\left( Z_i=1 \right)=\phi$。
使得$\hat{\phi}=\frac{1}{m}\sum_{i=1}^{m}Z_i$为所有随机变量的平均数，对于任意确定的$\gamma>0$，有
$$P\left( \left|\phi-\hat{\phi} \right|>\gamma \right)\leq 2 \exp( -2\gamma^2 m)$$
这意味着$\hat{\phi}$与$\phi$相差较远的可能性很低。

可以证得所有的假设的泛化误差有
$$\varepsilon(\hat{h})\leq\left(\min_{h\in\mathcal{H}}\varepsilon \left ( h \right ) \right )+2\sqrt{\frac{1}{2m}\log \frac{2k}{\delta }}$$

若$\left|\mathcal{H}\right|=k$且$\delta$与$\gamma$确定，对于$\varepsilon(\hat{h})\leq \min_{h\in\mathcal{H}}\varepsilon(h)+2\gamma$具有至少$1-\delta$的概率的情况下，
$$
\begin{aligned}
m&\geq \frac{1}{2\gamma^2}\log \frac{2k}{\delta}\\
&=O\left( \frac{1}{\gamma^2}\log \frac{k}{\delta} \right)
\end{aligned}
$$

当假设的数量变多的时候，$\left(\min_{h\in\mathcal{H}}\varepsilon\left(h\right) \right)$变小，同时，$2\sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}$变大。前者通常被视作偏差，后者通常被视作方差。
